{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Notebook to interact with gym-battery and battery-agent\n",
    "\n",
    "This python notebook is a working document to interact with and test the environment and the agent.\n",
    "\n",
    "Note: In order for this to work, gym-battery needs to be installed as a package, using pip install -e gym-battery from wherever gym-battery exists.\n",
    "\n",
    "The ipython notebook should exist in battery dispatch by default and should be ableto access those resources so it does not necessarily need to be build/installed using pip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import gym_battery \n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting the standard system, A10S Med busines large usage with a 2,000kW/10,000kWh battery\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('gym_battery:battery-v0', **{'N_actions':5})\n",
    "env.set_standard_system()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop partial day one and add a low-load period for 2 hours at the start of each episode\n",
    "import datetime\n",
    "env.load.DF = env.load.DF[76:76+31*96]\n",
    "env.load.DF.value = [min(2800., r.value) if r.start.time() < datetime.time(2,0,0) else r.value for ix, r in env.load.DF.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.load.DF.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.fit_load_to_space()\n",
    "env.episode_type = 'count_days'\n",
    "env.run_N_episodes = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: -1000.0, 1: -500.0, 2: 0.0, 3: 500.0, 4: 1000.0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the possible action mapping the agent can take\n",
    "env.action_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.   0. 600. 600.]\n",
      "to\n",
      "[   24. 10000.  5700.  6700.]\n"
     ]
    }
   ],
   "source": [
    "print(env.observation_space.low)\n",
    "print(\"to\")\n",
    "print(env.observation_space.high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the do-nothing value for taking no action\n",
    "def dict_key_by_val(d, val):\n",
    "    for k in d.keys():\n",
    "        if d[k] == val:\n",
    "            return k\n",
    "    raise ValueError(\"value not found in dictionary\")\n",
    "    \n",
    "act0 = dict_key_by_val(env.action_mapping, 0)\n",
    "act0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remember to set self.actions = env.action_space!\n"
     ]
    }
   ],
   "source": [
    "''' Set up the agent and the discretizer.'''\n",
    "from batterydispatch.agent.agents import DynaQAgent\n",
    "from batterydispatch.agent.discretizers import Box_Discretizer\n",
    "\n",
    "from batterydispatch.agent.policies import do_nothing\n",
    "agent = DynaQAgent()\n",
    "agent.set_policy(do_nothing, {'do_nothing_action': act0})\n",
    "\n",
    "# Note, you can change the size of the state sapce by changing the number of buckets, below\n",
    "agent.set_discretizer(Box_Discretizer(env.observation_space, N=[6, 4, 12, 12]))\n",
    "agent.actions = env.action_space\n",
    "agent.learning_rate = 0.05 # used for the updates of the Q estimates\n",
    "agent.subtype = 'on-policy' # Setup the MC agent for off-policy learning\n",
    "\n",
    "global eps\n",
    "eps=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 4.,  8., 12., 16., 20., 24.]),\n",
       " array([ 2500.25,  5000.5 ,  7500.75, 10001.  ]),\n",
       " array([1025.08333333, 1450.16666667, 1875.25      , 2300.33333333,\n",
       "        2725.41666667, 3150.5       , 3575.58333333, 4000.66666667,\n",
       "        4425.75      , 4850.83333333, 5275.91666667, 5701.        ]),\n",
       " array([1108.41666667, 1616.83333333, 2125.25      , 2633.66666667,\n",
       "        3142.08333333, 3650.5       , 4158.91666667, 4667.33333333,\n",
       "        5175.75      , 5684.16666667, 6192.58333333, 6701.        ])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.discretizer.buckets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the day of data that we will be trying to learn from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\administrator\\pycharmprojects\\gym-battery\\gym_battery\\envs\\battery_env.py:209: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  self.grid_flow.set_value(self.step_ix, 'state', tuple(self.state))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011-03-07\n",
      "96\n",
      "-421123.08\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJztvXl4I/d55/n54SIAngD7JrubaKllXZasVjfZieIoki/5GMt5Ys9j78xEO9GMPGtlJrOTcWLHmfXm8KwzyRPPZh87jjP2Rs54LF+yrXgd24psyeMkIrtbV6t19UF2N9k3AV64j9/+UVUgAIIHyCqQRL2f5+FDoKpQqALI+tZ7K601giAIgvvwrPcBCIIgCOuDCIAgCIJLEQEQBEFwKSIAgiAILkUEQBAEwaWIAAiCILgUEQBBEASXIgIgCILgUkQABEEQXIpvvQ9gKbZs2aIHBgbW+zAEQRA2FceOHbumtd663HYbWgAGBgY4evToeh+GIAjCpkIpdXYl24kLSBAEwaWIAAiCILgUEQBBEASXIgIgCILgUkQABEEQXIoIgCAIgksRARAEQXApIgCCIAjrQL5Y4qsj5ygUS+t2DCIAgiAI68APXrrExx87zs9OXVu3YxABEARBWAdGRuMAjCfS63YMIgCCIAjrgCUAE1MiAIIgCK4hkczx2uVZACbEAhAEQXAPR8aMu//ONp9YAIIgCG5ieDROwOfhnhu3iQUgCILgJkZG49yxu4fYlnYuz2bIFdYnFVQEQBAEoYnMZvKcuDDNUCxKXySE1nBxen2sABEAQRCEJnLsbIKShqF9vfT3hID1CwRv6IlggiAIrcbwaByfR3HHnh6uzeYAGF+nQLAIgCAIQhMZGY3zxv5uwgEfO7o9KLV+FoC4gARBEJpEOlfkxfEphmK9AAR8HrZ3BtctFVQEQBAEoUk8dz5BvqgZikXLy/oioQUWwI9fvczLF2YcPx4RAEEQhCYxMhrHo+DOgUh5WV9PiPGpVPm51prfeewlPvfUKcePRwRAEAShSQyfiXPzri66gv7ysr5IiItTGYolDRjN4S7NZKqsBKcQARAEQWgCuUKJZ88lGBzorVre1xOiUNJcmc0ARpYQwGCsd8E+7EYEQBAEoQkcn5giWygxWHNn3xeprgUYPjNJT9jP/m0djh+TCIAgCEITsO7sD1X4/4H5YjAzE2hkLM6hgSgej3L8mEQABEEQmsDwmTj7t3XQ29FWtdyyAMYTaS5NZzg7mWqK/x9EAARBEBynUCxx7GxigfsHIBzwEQn7mZhKM2K2iR5qgv8fRAAEQRAc55WLs8xlCwztq39h74+EmUikGT4zSUebj5t2djbluKQVhCAIgsMMj04CMDhQ37XT1xPi5JVZLkyluXNvBJ+3OffmYgEIgiA4zPBonL29YXZ0B+uu74uEOBdPcfLKXF03kVOIAAiCIDhIqaQ5MhZf9O4fDAsgXzQKwQ7vEwEQBEFoCU5emWMqlV/yzt7KBGrzeXhjX0+zDk0EQBAEwUlGTP//4UUCwGBYAAAH9kQI+Jp3WRYBEARBcJBnz02xvauNfvMuvx67o2F8HsXPXdec9E+LFQmAUmpMKXVcKfW8UuqouSyqlHpCKXXS/B0xlyul1J8ppU4ppV5USh2o2M8D5vYnlVIPOHNKgiAIG4fLMxn6ekIotXhlb3fIz2Mf+Xke+sV9TTyyxiyAe7TWb9JaHzSffwx4Umu9H3jSfA7wTmC/+fMQ8OdgCAbwSWAIGAQ+aYmGIAhCqxJP5oi2ty273W39PQT93iYc0TxrcQHdDzxiPn4EeF/F8i9rg2eAHqXUTuAdwBNa67jWOgE8Ady3hvcXBEHY8MSTOXrbA+t9GHVZqQBo4EdKqWNKqYfMZdu11hcBzN/bzOV9wPmK146byxZbLgiC0JJorUmkckQ7NqYArLQS+C6t9QWl1DbgCaXUq0tsW8/RpZdYXv1iQ2AeAtizZ88KD08QBGHjMZMpkC9qouGNKQArsgC01hfM31eAb2P48C+brh3M31fMzceB3RUv7wcuLLG89r2+oLU+qLU+uHXr1sbORhAEYQMRT+YAiG5WF5BSql0p1Wk9Bt4OvAQ8DliZPA8A3zUfPw78qpkNdBiYNl1EPwTerpSKmMHft5vLBEEQWpKyAGxiF9B24NtmCpMP+B9a6x8opY4AX1dKPQicAz5gbv994F3AKSAF/EsArXVcKfUHwBFzu9/XWsdtOxNBEIQNhiUAGzUIvKwAaK3PALfXWT4JvKXOcg08vMi+vgR8qfHDFARB2HzEk1kAIps5BiAIgiA0zqRlAWxQF5AIgCAIgkMkkjmCfg/hwMYcvSICIAiC4BCTyRy9K6gCXi9EAARBEBwinswRafev92EsigiAIAiCQ6y0D9B6IQIgCILgEBu5DxCIAAiCIDiGYQGIAAiCILiKTL5IKlcUARAEQXAbkxu8DxCIAAiCIDhCQgRAEATBnUxu8D5AIAIgCILgCOU+QCIAgiAI7mJyTiwAQRAEV5JI5fB6FF1BqQQWBEFwFfFkjkg4gMdTbxruxkAEQBAEwQEm53JEN3AfIFj5UHihAWYzef7jN17gd951E3t729f7cARBsIlnzkzy6b99lZLWC9Z5PYr/9J6bObAnAmz8KmAQC8AR/ufJa/zwxGUef37BzHtBEDYxXz9yntcvz9LbHljw8/KFGR57dry8bTy1sVtBg1gAjjAyaow6HhmTkceC0EoMj8a5+4at/Pk/v3PBuge+NMLwmfn/+Y3eChrEAnCEYVMAjp1NkC+W1vloBEGwg/FEiompNIOxaN31g7EoJ6/MMTmXpVAsMZXKb+hW0CACYDvTqTyvXprhxh2dpHJFTlyYWe9DEgTBBo6YFv1iAjBkLj8yliCRygMbuwYARABs5+jZOFrDw/dcD8Dwmcl1PiJBEOxgZDROZ9DHjTu66q6/rb+HNp+HkdE4idTG7wMEIgC2MzwaJ+D18Labt7Nva3s5HiAIwuZm+EycwYEo3kXy+gM+Dwf2RBgZmyxXAYsAuIzh0Ti37+4m6PcyFIsyMhanWFqYMiYIwubhymyGM9eSi7p/LAZjUV6+MMO5eBIQAXAVyWyBlyamy38kg7Eos5kCr16SOIAgbGaOjCaAxf3/FkOxKCUNPzpxGZAYgKt49lyCYkkzFOsFYND8LW4gQdjcjIxOEg54ubWve8nt7tgTwe9V/M+T14CN3QkURABsZWQ0jtejOLDXqATs6wnR1xMSARCETc7waJw790bwe5e+ZIYCXm7r7yFXLNEZ9C27/XqzsY9ukzE8GufWXV10tM3X1w3tizIyGkfXKR0XBGHjM5XK8eqlWQYHlnb/WFhuoo3u/gERANvI5Is8f35qgY9wKBZlMpnj9NW5dToyQRDWwpGxlfn/LaztNnoAGKQVxJp44fwUXxk+i9Ywnc6TK5TK/n8LKw7wu995id2RMABvvXk777hlR9V2k3NZvjJ8jofvuX7RNDPBObKFIp9/6gwfvnsfQb93vQ9H2ECMjE4S8Hm4fXfPirY/uDeCR7Hhq4BBBGBNPHrkPN88Ns6OriAAt/Z1MbSv+i5hoDfM3Tds5eTlWc5NpphK5zl2NrFAAL5+dJw/feJ17r1x27KBJsF+jp1N8Jm/e5037enh7hu2rvfhCBuI0WtJ9m1pX/GNQWfQz4cG92yK/2MRgDUwly2wJxrmqY/es+g2Sike+bXB8vMv/PQ0//n7r3JlJsM2UzgAhkeNiuHxRHpT/OG0Gulcseq3IFik80Xa2xq7VH7ql9/o0NHYi8QA1kAyW6Aj2NgfRjk1tKJTaLGkOWr6GSem0vYdoLBiUpYA5AvrfCTCRiOVKxIOtKZbUARgDcxlC7QHGhOAW3Z1EQ54q1JDX7k4w1zWuPBMJEQA1oN03rIApHurUE06V2zZuJAIwBqYyxSqUj5Xgt/r4c69kSoBeMZsGBdtDzCeSNl6jMLKyFgCkBcXkFBNJi8WAEopr1LqOaXU98znMaXUsFLqpFLqa0qpgLm8zXx+ylw/ULGPj5vLX1NKvcPuk2k2yVzjLiAwUkNfvTTLlNkxcGQ0zt7eMLf1d4sLaJ0ou4By4gISqknlioTEAuA3gFcqnv8R8Bmt9X4gATxoLn8QSGitrwc+Y26HUupm4IPALcB9wOeUUpv6U01mCw0Hh2A+DnBkLEGppDkyZnQZ7OsJiQCsE+UgsFgAQg3pvMtdQEqpfuDdwH8znyvgXuCb5iaPAO8zH99vPsdc/xZz+/uBR7XWWa31KHAKmE+P2YTMrsIFBHBbfzcBn4fhM5OcujpHIpVnMBalLxJiKpUnmZW70GaTkRiAsAjiAoL/CvwWYP139AJTWmvrSjUO9JmP+4DzAOb6aXP78vI6r9l0FIolsoXSqgQg6Pdyx+4eRsbi5YExQ7Fe+npCgGQCrQeSBSTUI18skS9q97qAlFLvAa5orY9VLq6zqV5m3VKvqXy/h5RSR5VSR69evbrc4a0byaxxwViNCwiMOMBLE9P8+NUr7OgKsjsaoj9iCoBkAjWd+SwgcQEJ81h/FyEXWwB3Ae9VSo0Bj2K4fv4r0KOUsq5+/cAF8/E4sBvAXN8NxCuX13lNGa31F7TWB7XWB7du3bgVmbNZY+ZnR9vq/jAGY72UNPzktasM7YuilKKvx2gVMS4WQNOxLvwpEQChAuvvwrUCoLX+uNa6X2s9gBHE/bHW+p8BPwHeb272APBd8/Hj5nPM9T/WRivMx4EPmllCMWA/MGLbmTQZywLoaPOv6vUH9vbgM3v+WM2jtnW24fcqsQDWgbSkgQp1KAuAW11AS/DbwH9QSp3C8PF/0Vz+RaDXXP4fgI8BaK1PAF8HXgZ+ADystd60/21W4Vb7Ki2AcMDHG/uNlg9DpgB4PIpdkgm0Llj/6BkHBODEhWlGryVt36/gPNYNQasGgRtyYGutnwKeMh+foU4Wj9Y6A3xgkdd/CvhUowe5EbEEYDVBYIv7btnBbKbAdVs7ysv6ekJSDLYOpPLOuYB+65svsrM7xH974KDt+xacxfp7aNU0UGkGt0qsVM3VFIJZfPju6/jw3ddVLevrCfH06xs3+N2qZBysA5hK5cvuPmFzYVmE4gISqii7gBrsBbQcfZEQV2azZAub1ju2KbEu/BkHLIBUrkDcrPoWNheWazBs8//5RkEEYJXMZQwB6FyDBVAPqxbg4lTG1v0KS2OZ+ikHLIBktkh8TgRgM5Iqp4G25qWyNc+qCSTLQWD7LQCQYrBmk3GoDiBXKJErlkjmio4EmAVnybR4DEAEYJXM5QoEfB78Xns/wn6zFkBSQZuH1pqU2QQuWyhRLC2oT1w1qYrmcvGkWAGbjfksIHEBCRXMZQp02nz3D7CjO4hHSTFYM8kVS5Q0dJnuPDvv1JMVFoUIwOYjJXUAQj1W2wl0OQI+D9u7gmIBNJGM2QCut8MY4m1nJlBlYz8RgM2H9bcQ9LfmpbI1z6oJzGUbnxO6Uoy20FIL0CxSZgO4aHsAsDcOIAKwuUnnCoT8XoyGxq2HCMAqmcvmHXEBgREIHhcLoGlYF/xI2BQAGy2AysKySRGATUc6X2zZPkAgArBqktniqttALEdfT4hL0xlbg5HC4lgX/F4HLIC5CgsgIQKw6UjnSi3r/wcRgFXjVAwADAugUNJcnpFagGZgXfCjHYYA2NkOojILSCyAzUc6X2hpC6A1c5uawGy2YHsRmEXlYJhd5mPBOWotADuzgObMrrE9YT/xZNa2/bYCpZLmufMJsvnVT2HrCvm5ta/bxqOqJt3C84BBBGDVJLMF29tAWPRH5msBDg048hZCBdYdvxUEttUCMF1Ae6JhCQLX8OSrV/jXXz669v385t1VDRXtpNVjACIAq6BY0qRyzmYBgVQDNwvrjj/Sbn8QOJktoJTxnb5+eda2/bYCZ67OAfDlXxukzde4N/r4xDR/+P+9YsRWHJodlc4V6TGTA1oREYBVkMw50wfIIhTw0tsekEygJmHFAHqdEIBckbDfS29HgPgZsQAqmZhK0xX08Ys3rO7q7TU7rDo5xS2dL7KrhS0ACQKvAqf6AFXSF5HBMM2i1gWUztk3GD6ZLRBu8xENB5hK5yWzq4KJRJo+0925GizXjJNT3FItHgMQAVgFTRGAnhATMhimKVgXkHkBWH1QspZkrkhHm49oewCtISFtoctMTKXL7s7VYF2Y7W7gV0kmXyQoFoBQyazVCtppAZhKY4xTFpwkky+ilHFBCfg89haCZQuEA16iZpsJqQUw0FoznkjTH1mDADTBAkibLrxWRQRgFVgD4Z12AWXyJckdbwIp859cKUXI77XVBTRn1otY8QX5Pg1m0gXmsoU1CUDYb/z/OWUBaK1JtXgWkAjAKpjL5oHVD4RfCeVMIAkEO05lql/I77W9FUR7wFtuMyGpoAbjZq+rtbiAguaQFqcsgGyhhNaIAAjVWMU9nW1+x95DBsM0j3RuXgDCAa+tWSVWxXhvhwhAJdaNTd8aLICA14PXoxyzAFp9HjCIAKyK+SCwc38YlcVggrNUVnsG/V6b5wEYBYNiAVRj3disxQIou+wcsgBafRYAiACsirkmZAF1h/x0tvnEAmgC6fy8AIQC9l5Qkmbb8IDPQ2fQJwJgMpFIE/R7yplXqyXot9diqyRdngcsAiBUMJct4PeqVVUvNoK0hW4OTrmAtNaGBWBair3tAQkCm1gpoGvtsx8O2GuxVZIWC0Coh+XXdXpIhJUKKjhLpQUQ9Htt8ymn80W0np8nG2kPSBqoycRUuuzmXAshv7eq46qdiAUg1GUu41wjuEoMC0CKwZymMgvIzjtKK124QyyABYwn0msKAFsEA17Sa+gmuhTWjUBYBECoZM7BVtCV9PWEmM0UmMnkHX8vN2MEgY3vM2SjT9m6M7UsgGh7QFpCY3wu8WRuTQFgi7DfS8ahGID1dxAUF5BQieHXbY4FAJIJ5DSGBWD8KwRtzCqpTRaItrcRT+ZcX919wXRrrqUIzCIU8JZnOtuNZQmGm2DtrxciAKtgLtMkAZBisKaQMgd/g2Hu2xUDsO4grSBwtN1PvqirxkS6ESuxwQ4LIGRjzKaWtNQBCPWYyxYc7QNkIcVgzlMqaTL5EqHAvAuoUNLki2v3K9ezAEBqAco1ADZZABmHYgBSByDUxcmB8JVs7WijzecRAXCQbMG4eFTWAYA97QVSVs8oU1ykH5DBRCKNz6PY1hlc876czALKSBaQUI85BwfCV6KUMttCiwA4xXygtkYAbHAr1FaMW0VP8TmXC8BUmp09wfJAl7UQtrlwr5JUroDXo/B7nU33Xk9EABrEKu5phgsIzFRQsQAco9bPa2ePeWtyXHtFFhBA3OUzASYSafp71l4DAFbrjhIlBwbtpHMlQmaX2FZFBKBBUjmjuKcZFgDIYBinscz8YEUdANjjArIsgHCtBeB2F9CUPTUAMG+xZQr2WwGtPhAeRAAaphl9gCrp6wlxbS7nWLm727ECfeGKSuDK5WshmSuaLUPmxaXN53G1AOQKJS7NZGzJAIIKwXYgEyhdkR3WqiwrAEqpoFJqRCn1glLqhFLq98zlMaXUsFLqpFLqa0qpgLm8zXx+ylw/ULGvj5vLX1NKvcOpk3ISSwCaUQgGkgnkNOV+L4FqF5AdgmtMA5v/O1FKGdXALo4BXJrOoLU9GUBgr2DXks4XW7oKGFZmAWSBe7XWtwNvAu5TSh0G/gj4jNZ6P5AAHjS3fxBIaK2vBz5jbodS6mbgg8AtwH3A55RSm+7TLQf2mlQcIrUAzpLKV1d7WhdsOy4oc1ljHnAlkfaAq+cCW4Ng+m2yAOwU7FrS+VJLVwHDCgRAG8yZT/3mjwbuBb5pLn8EeJ/5+H7zOeb6tygjinI/8KjWOqu1HgVOAYO2nEUTmcs02QUkFoCjZGr6vYRsnDKVyhUW3EFGXd4PyI5BMJVYn68jFoC4gAyUUl6l1PPAFeAJ4DQwpbW2EnDHgT7zcR9wHsBcPw30Vi6v85pNQ7NdQDu6jHS583EJBDvBgiwg0wKwo79MvXThXpf3A7owlUEp2NltrwXgRCqouIBMtNZFrfWbgH6Mu/ab6m1m/q6XM6WXWF6FUuohpdRRpdTRq1evruTwmko5ta9JFoDP6+GG7Z28MD7VlPdzG6laC6DsU157cVEqt7BgsCccYDrl3uZ+iVSOTnNAjh0EbczaqiWVK5b336o09C1oraeAp4DDQI9SyroK9gMXzMfjwG4Ac303EK9cXuc1le/xBa31Qa31wa1btzZyeE1h3gXUvD+MoViUY2cT5ArOlLy7mdo00Pk7yrV/1smaIDAYluNctuBI3vpmIGVzI0Uns4AyFaNCW5WVZAFtVUr1mI9DwFuBV4CfAO83N3sA+K75+HHzOeb6H2uj/eHjwAfNLKEYsB8YsetEmkUzBsLXMhSLksmXeOnCdNPe0y3U9nsJ+u2LASRzhQVB4K6gn5KetyTdRjJrr1vFzsK9WtzgAlqJFO8EHjEzdjzA17XW31NKvQw8qpT6Q+A54Ivm9l8E/lopdQrjzv+DAFrrE0qprwMvAwXgYa31pktuT2YLeNT8haIZHIpFARgZjXNgT6Rp7+sG0nkjV9/vNb7P8qBxGy7Q9S52VuxoNlOgM9i8m4iNQj1RXAt29m6qJeUCC2DZb0Jr/SJwR53lZ6iTxaO1zgAfWGRfnwI+1fhhbhzmssYfcDPLw7d0tHHd1naGz0zyb+6+rmnv6wbSueKCVD+7BsMns3UsgJBx0Z/J5NmFPYHQzUQqW7S1v75TFkCppMkWSlIJLFQzV+efuhkM7evl6FiCokt9x06RrnOXZ8dUsEKxRLZQqhsDAJhJu9MFZHcjRaeygKzWEq1uAYgANEiySZ1AaxmKRZnNFnjl4kzT37uVqefnDdkwFzhZMwzGost0+8y6dMynEQS276Lq83oIeD221wGkairEW5WWnHWWLRS55lC5/WQyR0eTagAqOTRgxAGGR+Pc2tfd9PdvVdL5hS4gO6aCpRZJF650AbmRuWzR9huooN9jeyVw2gXDYKBFBeDVi7Pc/9m/d2z/97yh+empu3pC7I6GGBmd5MFfiDX9/VuVdG5hx8egDS6g5CJNAyuDwG4klSvQbvNddcjGMZ4WaRcMg4EWFYD+SIj/8iu3Obb/QTMrp9kMxXp58pXLaK1bukd5M6nrAvJ7mVpjv55keRpY/SygmbT7LIBSSZvFcfZedsIBX7mnk12IBbCJ6e1o458e2r38hpuMwViUbx4b59SVOfZv71zvw2kJUrkikXB1OmY44OXitD0WQG0QuM1ntIR2owVgXaTtbqQYdGAwvFssAAkCbyKGTMvjmdH4Oh9J65DJF8v9fyzsyAKygsD1Msa6Qn5XxgBqB+TYRUhiAKumJS2AVmVPNMyOriDDZyb5F4f3Vq07H0/xe39zojzkPOD18Il338S+rR2L7u/Y2ThPvHyFj73zxjUf25XZDH/yw9f4T++52fYCp794+jTXbe3grTdvr1r+0sQ0jz07we+++yY8FfNliyXN7zx2nAvT8x1UPzS4h3e9ceeCfRtpoNX3QUE7soCWuNh1Bn3MuNACsD4Tu9OowwGf7YPhLQvAzpqFjYhYAJsIpRSDsShHxuIY3TXmefyFC/zdK1eYzRSYyxb4yWtX+M7zC1otVfH//v0Yn3/6NOM2jJz83gsX+frRcZ56zd4Gfpl8kT/50Wt8/unTC9Z9ZfgsX/r7UU5emata/srFGb529DwXpzPMZQscn5jmL356pu7+U3Va/oZtsQAWv9h1Bf2ujAFYcRG7L6pBv9eW3k2VuMUCEAHYZAzGolyeyXKupj308GicG7Z38J2H7+LbH7mLW3Z1M3xmctH9aK0ZNl1JR8bW7lIaHjXea8Rm99Sz5xLki5oXxqcW+Hmt47feu3b5Xz84yLc/chf/fGgvL01Ml1t5V5LJlxa6gMxK4FqRbYRU+WInFoDFfCddey+qRtquvZ9neVBQoLUvka19di2IFQcYPjN/oS0USxwbizMU663a7rnzU2QXGZY9Npni6mx2wb5Wg9a6fOGvvRivFWu/+aLmufOJ8vIrsxnOXE2a7xmvec0ke6Lhcs/5oX1RiiXNs2cTVdsViiVyxdLCSuCAF60pu9NWw9wiQWAwYgBuLAQr10bYbAGE/Pa07qhkflCQuICEDcT12zqItgeqLnovX5whmStWpacOxqLkCiVeHK/fQXTEvFDv29K+5rv2U1fmSKTy7NvSzuuX52wdej4yGmdvbxilqq2LI6PGxdw6futu3RKjys/iwJ4IXo9acJ7zmR7V/wZ29JexXEtez8J0XcMF5D4LwOqka3caqBN1ALVdYlsVEYBNhlKKwYEoI2Pzd9rWha3yomdVDi92cR8ejdPbHuCfHtrNmWtJrsxmVn1Mlhh95J7rAXtcSgC5QolnzyW45w3buHlnV9W5jIxOEg54+V/vGuDqbJaxScMlZolR5WfR3ubj1r7uJQRgYRZQ5frVsFTFa1fQ504LIOuMC8iu5n2VpPNFAj5PXQFvJUQANiGDsSjn42kumHOCnzkTZ6A3zPauYHmbSHuAN2zv5JlF4gDDZ4y75MP7DLeRdUe9GoZH42zvauOf3L6TNp/HtjjA8YkpMvkSh/dFGYxFefbc/FCc4dE4d+6NcNf1W4zn5nlaKbJDNcV6Q7Eoz5+fqsruWSzQZ0eL4aV63nSF/GQLpUXdc63KUm6xtRDye8kXNfmifYHgTL71W0GDCMCmxLq7PTIWp1TSHBmL161OHjQniRVq/jHGEykmptIMxaLcsquLcMBbdgk1iuFymWQo1kubz8sde3psEwDLsjg0EGUo1ksmX+L4xBRTqRyvXZ5lcCDKvi3tbOkIlN9zxBSjPdFw1b4GB6LkiiWePz8/WrN2HrCFHS6getPALNzaDsJyq9jeCsL8vuysBaiXHdaKiABsQm7a2UVn0MfwaJzXr8wync5XBYAthvZFSeWKnLhQ3UHUctEMxnrxez3cuTeyIJC6Us7FU1yeyZYFaDDWy4kL07YUOo2Mxrl+Wwe9HW0cGjAG4QyPxjk6lkBrQ+Cs1NhhMw5giVFtq4xDA9EFcYR0rn6mjh0WQDJI+N2SAAAbYUlEQVRbpGMxC8Csk3BbKmgyW6DN58HntfeyE3JgLGQ6X2r5aWAgArAp8XoUhwaiDJ+ZLGfw1LUAFokDjIzG6Qr6eMOOzvJ2r16aXVX/m+Eal8tQLEpJw7Gzq3cpgVHMdXQsUT6v3o429m/rYPhMnOHRSQI+D7fv7ikf/8RUmn84PVklRpV0h/3cuKOrrgDU6wYKrKkWIJkTC6AWu6eBWTgxE6DeoKBWRARgkzIYi3L6apLvH7/Iru4g/ZGF06W2dQWJbWlfmCd/Js6hgWg5wDVkxQHGGr9oD5+JE20PcP02o+L4wJ4IvjoZN43y8oUZ5rKFKl++5dL6h9OTvGl3T/kf1Dr+/+fHJ43nizTrGzJfb/mK56s9F3YDhbW7gBa72Lm1JXQyW7S9DQTMWwB2zgRI5wst3wcIRAA2LdZd7rCZ8rhYd9DBgSgjo0asAMz8+WvJqrvk2/q7Cfg8q4oDjIxNcmggUn7/UMDLbf0LM24axRKt2tTWuWyBExdmqi7yb9jeSVfQxzM1YlTLYCxKOl/k+ISRGrtYwy/rzn0tPuVUbvGB4m6dCpbMFmyvAQBn5gKnl/j+WgkRgE3KG/u6y6bvYB3/v8VgLMpMpsBrl2eB+Wwf664ZjDveN+1uPHh7YSrN+Xh6QfxhMNbLi3UqdxthZDReVcwFVL1PpTB4PKr8vFKMaqlNjV0s19t6vpY7yqVGH7p1Klgy58w0vXIQ2EYLIOUSF1Brl7m1MFbw9menrjG0b/H5BNa6P/rBq+zf1sHRswnCAS+37Oqq2u5wLMpnnzrNH37vZVY6asBqR1Hrcx/aF+XzT5/mE98+Tm9HoIGzmucfz0xy3y07qpbt6A6ytzfMRCLNnXsj1e8Z6+XvXrlSNxhusbWzjeu2tvONo+eZnMvysjles9YCWKtPWWur7/3iaaDgThdQpwPT9OyI2dSSqTMnohURAdjEvO+OPgqlEvu2tC+6TX8kzFDMcANZd77vvX0X/ppMjLffsoO/fuYs/2PkXEPHcPPOLm7aWS0mhwaiDPSG+cGJSw3tqxKvR9Xt3vkrB/oZu5ZcEGB9283b+eqRc7z1pu0LXlPJL9/Rx+eeOs1Xho3z3L+tg+5QdffS9jYvHgXTqxwKc3E6Q7Gk2drRVnd9e8DYv9uCwKlcgZ3dweU3bBAngsBzS6TxthKtf4YtzPvv7Of9d/Yvu93XPvxzy25za183z/0fb7fjsOho8/HUR++xZV+1/Lu37K+7fGBLOz/+zV9a9vW/fu9+fv3e+vuw8Hk9bO8KMj6VXnK7xbCE9uBAfctMKUWnCzuCJrNFRy6qQZsFoFTSJFJ5ettXZ71uJiQGIAh16I+EmEisTgCGR+N0Bn0LLKNKOoM+11kARhqo/W6VsM11ANPpPMWSJioCIAjupK8nxMSqLYDJqjTbenQF3TcVLJktEHYiCGxzFlDcdP2tNn61mRABEIQ69EVCXJrOLGijsRxXZ7OcvpqsW4xWidtmAuQKJfJF7UghWNBnbxDY6mYbCYsACIIr6esJUyhpLpszE1bKfJuNpQWgK+SuGEB5RKYDmTUejyJo41zgyTlDAMQFJAgupc+srG40DjAyGifk9/LGvu4lt3NbDGB+GpgzeSchv30zASwLQFxAguBS+npMAZhqbF6y1aa6Ns22FrfFAKx5wE5UAoMhAHa5gBIpcQEJgqspC0ADFsB0Ks+rl2aWdf+A4QKayxbKLTpaHcsCcKIXEBiBYDtdQO0BrysqgUUABKEOoYCX3vZAQ5lAR8biaL14M7pKuoI+tIY5m4eZb1SsGIATQWCwdypYPJkl6gL3D4gACMKi9EVCjDdgAYyMxQl459tUL4XbZgJYLiCn2iuE/b7y0Pm1MpnMEW2vX8XdaogACMIi9EcaqwUYHo1XtaleCrfNBLAuzk5ZAMGAl3TenpGQiVSOaNi//IYtgAiAICxCX0+IC1NptK7vp09mC3z3+Qm+dWycbxw9z0sT0yvy/0NFQzjTAtBa84+nJymuISaw2OvHriU5H28smG03SYfmAVuE/B7SDVoApZKuOzM7PicWgCC4nr6eEJl8iclk/aZw33p2nN949Hl+8xsv8NFvvkixpLn7DVtXtO/yTADTAhgZjfOhv3yGn568uqpjffnCDB/6y2f4mxcuLFj3b/77Mf79155f1X7tImlm6DhlAYQDvoZjAE+/fpUPfuEZXqiYE621ZjKZc0UKKKxAAJRSu5VSP1FKvaKUOqGU+g1zeVQp9YRS6qT5O2IuV0qpP1NKnVJKvaiUOlCxrwfM7U8qpR5w7rQEYe30RYzB8ovFAS7PZPB6FE9/9Jf46UfvYeR33lKeObActTMB/tG8E708nVnVsY5NJo39nK6+o40nc7x6aZYXzk/Z5iNfDclsAaUg6HfmnjPo95LONeYCGr1mfGbWZwdGNXG2UHJFERiszAIoAL+ptb4JOAw8rJS6GfgY8KTWej/wpPkc4J3AfvPnIeDPwRAM4JPAEDAIfNISDUHYiCyXChpP5oiE/eztbWdPb5htXStvdVzrArI6iC5mbSyHdYy14z+tyuRCSfPs2akFr2sWyWyR9oBv0WE9a8UoBGtM4CxhrxR4qwgs6oIaAFiBAGitL2qtnzUfzwKvAH3A/cAj5maPAO8zH98PfFkbPAP0KKV2Au8AntBax7XWCeAJ4D5bz0YQbKRcDbxIMdjkXG7Vd4qVQeBcocSz54xJbfHVCoAZrB6bTHF5Zt6KGD4TJ+Dz4FGsauSnXSSzhUUH5NhB2EwDXSxeUw/re60rAGIBLEQpNQDcAQwD27XWF8EQCWCbuVkfcL7iZePmssWWC8KGpDvkp7PNt6QFsNoLhd/rIeT3MpPJc3xiioyZwbJaARhPpAn4jH/nytGeI2OTHNjTwy27uhle45zmtZDMOTMP2CIU8FLSkGugeZ8lmpWZXmUBkBhANUqpDuBbwL/XWs8stWmdZXqJ5bXv85BS6qhS6ujVq6sLiAmCXfQtkQoaT+XoXUO2iNUPyLow90dCa7IADu/rpT3gLQvATCbPyxdmGIz1MhiL8tz5KbIF+6ZmNUJyiRnJdlAeCtNAOwhL2CcS8xae5YJzwzAYWKEAKKX8GBf/r2itHzMXXzZdO5i/r5jLx4HdFS/vBy4ssbwKrfUXtNYHtdYHt25dWUaFIDhF/xLFYPFkjkj76vPFu0JGP6CR0TjXb+vg+m0dqxeARIq90TB3DkTLcYBjZxOUtDHveSgWJVco8eL49KqPdy0kc87O2A03OBMglSuQSOXxeRQTFam+CasVtAiAgTKiNl8EXtFa/2nFqscBK5PnAeC7Fct/1cwGOgxMmy6iHwJvV0pFzODv281lgrBhWWwwTKFYYiqVX1O+eGfQx1Qqz9GxBEOxKNH2wKoEYDaTZyZToC8SYigW5fXLc8STOUZG4/g8ijv2RMrZScN18t6bQTJbcCwFFObnAq+0IZx1939rXzeZfKn8uU8mc/i9ik4Hj3UjsRIL4C7gXwD3KqWeN3/eBXwaeJtS6iTwNvM5wPeBM8Ap4C+BjwBorePAHwBHzJ/fN5cJwoalLxJiNlNY0LkzkTKer8VV0BX089y5KeayBQZjUXrbA0wmG5s/APM+7L6eULkP0ZGxOCOjcW7r7yYU8BJpD/CG7Z3rFgdI5YqOTAOzCDU4FtKa92x9XtZnGE9mibYHHMtW2mgs+41orX9Gff89wFvqbK+BhxfZ15eALzVygIKwnvT1GLUAE4k0XTvn3T1Wy+C1ZIt0BueLl4ZivVyYypDJl0jniuUL2koYjxsXr/5IiJt3ddHm8/D061d5cXyKf/XmfeXthvZF+eaxcQrFEr5l2lXbTTJboN1BF5BlAay0I6hlAQzGovzFT88wkUhzW3+PmdrrDvcPSCWwICyJlQpaGwewY2qUVQuwtzfMju4gUTOe0KgVULYAIiHafF7u2NPDt46Nky/qqtYUg7EoqVyRExeWyuFwBqeDwJZgrtgFNJXG7zXcY9ZzMOI6bqkCBhEAQViS+WKw6loAO/LFrWrgQdM/b8UTGo0DTEwZKaBbzNcPxnrJFkp4FNy5d77W0nqfkSa7gUolTSpfbIoFsNIg8EQizc7uEJGwn442X1ng4y7qBAorcAEJgpvZ0hGgzedZEAiOm3fpa4kBWMVg1l26JSaNVgNPJNL09YTweAxPreXXvnlXV1lkALZ1BYltaWd4dJJ//Yv7Fuzn3GSqHOtQCvZv6yzXFqwFo0DLuXGQMG8BnLoyR1/Pwkyn3dEw3aH5z2JiyvjMlFL09cxnek0mc65JAQURAEFYEusCsVAAjAvlWtIFt3cF8Sg4vK8XmBeTRIMCMG5ezCwO7IkQ9Hu467otC7YdikX5/vGLlEq6LBgAp6/O8dY/fZrKQtqH77mOj77jxoaOpR7z08Ccu9xYF/c//uFr/PEPX1uw/k27e/jOw3eVn48nUrx5v5FmbtV65AolZjMFV8UARAAEYRn6IqEF1cDxZJbOoG/Z2b9L8d7bd/HGvm52R41AsyUmDbuAEmnecuO28vNQwMv3/u2b2dm9sDfRYCzKo0fO89rlWW7a2VVe/g+nrqE1/MkHbqcr6OP/fvIkPzt5jY++YzVnVo01DKbDwVYQWzraeOwjP8+12YXxkx+9fJlvPTvOdDpPd8hPrlDiymy2LJp9PSGOjsWZSrmrChhEAARhWfojIZ64WB04tcNVEPB5eMOOzvLzrqAPv1c15ALK5Itcm8uWg9UW12/rqLu95W4aGY1XCcAzo3F2dQf5lQN9KKV4aWKazz51mjkb8vedngVgcWBP/d6SXSE/3zw2ztGxOG+5aTsXp9NoPR/g74uEmMkUOGvOTHCTC0iCwIKwDH09Ia7N5apSDNfSB2gxlFJEwgHicysXgAsVNQAroT8Spq8nVBUI1lozMhpnMBYt578PxnopljTHziYaOIP6OD0PeDnetLuHgNdTPmfLmuuvsAAAjptV0m5pBAciAIKwLPNdQaubhjmRLRJtDxBPrVwArOBlf2RlAgCGFTA8OllufzA2meLqbJbBWG95mwN7e/B5lC0dRK3UTCdbQSxF0O/l9t3zzfCsIrB+c96D9dkdnxABEAShhspiMAtDAOyfG9toO4jKGoCVMhSLcm0uxxlzIIp1ka+sGQgHfNza121LyqgVBHYyC2g5BmNRXpqYJpktMJFIoxTsMGMk1mf34rgxL0EEQBCEMrXFYFprY3C4UxZAIwKQSOP1KHY0MIymMg4AxsyA3vYA121tr9puKBblhfPTK66uXQzLBbS+AtBrDMU5l2BiKs32zmA5xXVLexsBn4cz15IohauygEQABGEZtne24fWo8gCR2WyBfFE7EizsbQ8wObfySuCJqTQ7uoINtXaIbWlnS0fbvADU+P8tBmNRcsUSz59f2yQxKwvIyUKw5bhzbwSvRzEyGjfqJiosJo/HSPXVGnpCfrwed/QBAhEAQVgWn9fDjq5g2QUUt6ENxGJE29uYyRTIr3CwiVUE1ghKKYZiUUZG44wnUkxMpcvFY5UcHIiilGEhrIVmZQEtRUebj1t3dTE8Gi8XgVViPXdLG2gLEQBBWAGVg2EmHRwbaMUVEisMBE9MpRvy/1sM7YsyMZXm289OAFQFgC26Q35u2tHFyNjaAsHJXJGA12NLVfFaGIxFef78FBenF35mlgC4KQUURAAEYUX098wXgzk5N7aRfkCFYolLM5mGLQCYjwN88e9H6Qr6quoRarc7djZBrrDyUYu1OD0PeKUMxnrJFUrki3qhBWAKgpsCwCACIAgroj8S4tJMhnyxVG7V4IwAmNXAK6gFuDSToVjSDaWAWtywrZPukJ+pVJ5DA9FF/d5DsSiZfImXLqx+klgyV1hX94/FoYH5QrHaz6y/LADuaQQHIgCCsCL6IiFKGi5NZ+bnxjrQMsDa50pqAayspNW4gDweVZ4SNljH/29xKGZNElt9HGCjWAA94QA3mpZOrQBYFoETqb0bGREAQVgB5VqAqTTxZJY2n6fcgthOrBTEShfQbzz6HP/n4ycWbHvebF2wGhcQwOF9xsV9aN9C/7/Flo42rt/WUZ4zvBhXZ7P83P/1ZN2RkzNpZ2cBNMJQzAhs76r5zKx+TFs73GUBbIxvRRA2OOVq4ES63AfIibGBkbA5FMZ0AWXyRf72+CU6gz4++U9urnrP585P0dnmY29ve919LceHBvfQ2xHg9v7uJbcbjEX5m+cvUCzpRV1F/3D6GhenM/zgxKUqQSmWNC9dmOY9t+1a1THazcP3XM9d129Z4JLa1RPis//LAX5h/8IOqq2MWACCsAKszpoTU2kSyZxjHSN9Xg89YX/ZAnjh/BS5YonJZI7TV5NV2w6fmeTgQGTVeevtbT5++Y7+ZYVsKBZlNlvglYuLTxKz2izUVg6/emmG2UyhbprperCtK8jbb9lRd927b9tZNTPADYgACMIKCPq9bO1sYzyRcnxqVGU/oMoh7pUX12tzWU5fTdZN37QbK0aw1EB5y/Xz8sUZptP58nLrmJeKMwjrhwiAIKwQazDMZDJHNOzcnWK0oiPoyGicG3d0srWzraox25EmXlh3dofYEw0v2hjOEqO7b9iK1nDsbLVo9UdCC3zuwsZABEAQVog1GKYpFkAyR75Y4tjZBIf39ZodPOPlDp7Do3FCfi9v7Fvaf28Xg2blsK4cGWZiidGHf3Effq8qWwpWm+mhJlgpwuoQARCEFdJvzo5N5YqOpIBa9HYEmEzmOD4xTTpfZDAWZSgW5eJ0ppz6OTwa58DenqZV1w7GoiRSeU5dmVuwzhKjgwNRbuvvKbt9Tl+dYzKZ2zD+f2EhIgCCsEL6IyEKJeMO2MmK0Wh7gEQqV869PzQQLd9FD4/GmU7lefXSDIMDzbuzPmy+/zN14gCVYjQUi3J8fJpUrlC2BMT/v3ERARCEFVJZcOVky+BIOECxpPm7Vy5z3dZ2tna2sX9bBz1hPyOjkxw9G0fr5l5Yd0dD7OgKLsjyscTIEqjBWNRou3x2ipHRONs629jbG27acQqNIXUAgrBCrGIwcKYKuHbfx84m+NDgHmC+cndkNE4kHCDg9XDHnh7HjqEWpVTVJDErdbRWjO7cG8GjYHh0kuEzcYb29TpSLyHYg1gAgrBCKi0AZ11A8wHmSv/5UCzK2GSK7790kdt3dxN0oBJ5KQZjUS7PZDlnViCDkeUT8Hp4025DjDqDfm7t6+Y7z09waSYj7p8NjgiAIKyQjjZfuVDIybbBlfserBIAw81yPp5elwur1Tqisi/QM6PxBWI0OBDlfNwIVksAeGMjAiAIDdDXE8LrUXQFnasDsIaS1ObP37Szkw6zp04zCsBquW5rB9H2QDm4m8wWeGlieoEYWc8jYT/Xb+1o+nEKK0diAILQAH2REFdmM3gcHBtoWQC1F1af18OdeyP87NQ17twbqfdSR1FKMTgQ5XsvXuDF8SmyhRLFkl4gRlaX0UMDUUc/J2HtiAAIQgM8+Asxzk5uc/Q9gn4vv33fjdx9w9YF6x6+53p+6Q1by5ZAs/lXb47h9Sg0RjrsXddvKbuGLCLtAX733Tdxx57mi5TQGKpeZd9G4eDBg/ro0aPrfRiCIAibCqXUMa31weW2kxiAIAiCSxEBEARBcCkiAIIgCC5lWQFQSn1JKXVFKfVSxbKoUuoJpdRJ83fEXK6UUn+mlDqllHpRKXWg4jUPmNufVEo94MzpCIIgCCtlJRbAXwH31Sz7GPCk1no/8KT5HOCdwH7z5yHgz8EQDOCTwBAwCHzSEg1BEARhfVhWALTWPwVqWwDeDzxiPn4EeF/F8i9rg2eAHqXUTuAdwBNa67jWOgE8wUJREQRBEJrIamMA27XWFwHM31ZidB9wvmK7cXPZYssFQRCEdcLuIHC9sj+9xPKFO1DqIaXUUaXU0atXr9p6cIIgCMI8qy0nvKyU2qm1vmi6eK6Yy8eB3RXb9QMXzOW/VLP8qXo71lp/AfgCgFLqqlLq7CqPcTVsAa418f02Gm4/f5DPQM6/Nc5/70o2Wq0APA48AHza/P3diuW/rpR6FCPgO22KxA+B/1wR+H078PHl3kRrvbAW3kGUUkdXUj3Xqrj9/EE+Azl/d53/sgKglPoqxt37FqXUOEY2z6eBryulHgTOAR8wN/8+8C7gFJAC/iWA1jqulPoD4Ii53e9rrRfOlhMEQRCaxrICoLX+0CKr3lJnWw08vMh+vgR8qaGjEwRBEBxDKoGr+cJ6H8A64/bzB/kM5PxdxIbuBioIgiA4h1gAgiAILsXVAqCU+t+VUieUUi8ppb6qlAoqpWJKqWGzZ9HXlFLODX9tMnb1ddqsLHL+f6yUetU8x28rpXoq1n3cPP/XlFLvWJ+jto9651+x7j8qpbRSaov53BXfv7n835rf8Qml1H+pWN5S3389XCsASqk+4N8BB7XWtwJe4IPAHwGfMfscJYAH1+8obeevWGNfp03OX7Hw/J8AbtVa3wa8jpmerJS6GePv4RbzNZ9TSnnZ3PwVdVqwKKV2A2/DyOizcMX3r5S6B6OFzW1a61uAPzGXt+L3vwDXCoCJDwgppXxAGLgI3At801xf2edo02NTX6dNS73z11r/SGtdMJ8+g1GkCMb5P6q1zmqtRzFSmwebdrAOsMj3D/AZ4Leors53xfcP/G/Ap7XWWXMbq6i15b7/erhWALTWExhqfw7jwj8NHAOmKi4IbuhZ1Ghfp1bm14C/NR+74vyVUu8FJrTWL9SscsX5AzcAbzbdvk8rpQ6Zy11x/q4dCm/6uu8HYsAU8A0Ms7cWt6ZJrbh/UyuglPoEUAC+Yi2qs1lLnb9SKgx8AqMyf8HqOsta6vxNfEAEOAwcwihw3YdLzt+1FgDwVmBUa31Va50HHgN+HsPUtYTR6mXUyly2TPsV9nVqOcwBRe8B/pmez4t2w/lfh3ED9IJSagzjHJ9VSu3AHecPxnk+Zrq6RoASRj8gV5y/mwXgHHBYKRVWSimMyuaXgZ8A7ze3qexz1KpYfZ1gYV+nXzWzQQ5j9nVajwN0EqXUfcBvA+/VWqcqVj0OfFAp1aaUimEEQ0fW4xidQmt9XGu9TWs9oLUewLjoHdBaX8Il3z/wHYy4H0qpG4AARjO4lv/+AdBau/YH+D3gVeAl4K+BNmAfxhd9CsMt1Lbex2nj+X4VI96Rx/hnfxDoxcj+OWn+jprbKuCzwGngOEa21LqfgwPnfwrD1/u8+fP5iu0/YZ7/a8A71/v4nTj/mvVjwBaXff8B4L+b14BngXtb9fuv9yOVwIIgCC7FzS4gQRAEVyMCIAiC4FJEAARBEFyKCIAgCIJLEQEQBEFwKSIAgiAILkUEQBAEwaWIAAiCILiU/x8tNLz18Xt5EQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "done = False\n",
    "state = env.reset()\n",
    "i = 0\n",
    "while not done:\n",
    "    i+=1\n",
    "    _,reward,done, details = env.step(act0)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(env.grid_flow.net_flow)\n",
    "try:\n",
    "    print(list(env.grid_flow.start_date)[0])\n",
    "except:\n",
    "    pass\n",
    "print(i)\n",
    "print(reward)\n",
    "default_reward = reward\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We then initialize the agent state-action estimates, based on the original billing period.\n",
    "# We also give the do_nothing action a small bonus of 100, in order to prevent the agent from arbitrarily taking action.\n",
    "agent.initialize_state_actions(new_default=default_reward,\n",
    "                              do_nothing_action = act0,\n",
    "                              do_nothing_bonus = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'do_nothing_action': 2}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.policy_args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the function to run the episodes, and run episodes until convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from batterydispatch.agent.functions import log_history, run_episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DynaQ-Learning Agent'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We then set the final parameters guiding the episodes: The agents proclivity for random actions, \n",
    "# the number of episodes without a policy change before we can say we've converge.\n",
    "agent.set_greedy_policy(eta=0.125)\n",
    "agent.patience = 100\n",
    "agent.planning_steps\n",
    "agent.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.learning_rate = 0.075\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONT USE; Run of a DynaQ agent on Stochastic Day with seeds, run for 10,000 episodes: Seed 13\n",
      "2636 | Current reward of -421123 / -421123, 5700.0 / 5700.0, patience=1\n",
      "2637 | Current reward of -400475 / -403427, 5600.0 / 5700.0, patience=1\n",
      "2638 | Current reward of -391169 / -391169, 5400.0 / 5400.0, patience=1\n",
      "2639 | Current reward of -423763 / -401353, 6700.0 / 5700.0, patience=1\n",
      "2640 | Current reward of -403731 / -382050, 6100.0 / 5700.0, patience=1\n",
      "2641 | Current reward of -396472 / -392357, 4400.0 / 4200.0, patience=1\n",
      "2642 | Current reward of -379472 / -369334, 4400.0 / 4500.0, patience=1\n",
      "2643 | Current reward of -401107 / -395325, 5600.0 / 5400.0, patience=1\n",
      "2644 | Current reward of -395479 / -394931, 5700.0 / 5700.0, patience=1\n",
      "2645 | Current reward of -372905 / -373641, 5100.0 / 5100.0, patience=1\n",
      "2646 | Current reward of -391864 / -392601, 5400.0 / 5400.0, patience=1\n",
      "2647 | Current reward of -399863 / -387697, 5400.0 / 5400.0, patience=1\n",
      "2648 | Current reward of -357987 / -336974, 4300.0 / 3600.0, patience=1\n",
      "2649 | Current reward of -368223 / -364212, 4400.0 / 4200.0, patience=1\n",
      "2650 | Current reward of -440848 / -434269, 5400.0 / 5400.0, patience=1\n",
      "2651 | Current reward of -388411 / -389989, 5400.0 / 5400.0, patience=1\n",
      "2652 | Current reward of -390076 / -381072, 5400.0 / 5400.0, patience=1\n",
      "2653 | Current reward of -405211 / -405316, 5400.0 / 5400.0, patience=1\n",
      "2654 | Current reward of -333077 / -328308, 4400.0 / 4200.0, patience=1\n",
      "2655 | Current reward of -443664 / -433008, 6200.0 / 5700.0, patience=1\n",
      "2656 | Current reward of -474297 / -474297, 5700.0 / 5700.0, patience=1\n",
      "2657 | Current reward of -371670 / -369559, 5500.0 / 5400.0, patience=1\n",
      "2658 | Current reward of -360861 / -354470, 5200.0 / 5100.0, patience=1\n",
      "2659 | Current reward of -333388 / -320074, 4400.0 / 3900.0, patience=1\n",
      "2660 | Current reward of -382590 / -365265, 5800.0 / 5100.0, patience=1\n",
      "2661 | Current reward of -355877 / -339806, 5600.0 / 5400.0, patience=1\n",
      "2662 | Current reward of -357609 / -367657, 4200.0 / 4800.0, patience=1\n",
      "2663 | Current reward of -353339 / -339634, 4500.0 / 4500.0, patience=1\n",
      "2664 | Current reward of -355336 / -349958, 5200.0 / 5100.0, patience=1\n",
      "2665 | "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2656\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2657\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2658\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'load'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mset\u001b[1;34m(self, item, value)\u001b[0m\n\u001b[0;32m   1052\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1053\u001b[1;33m             \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1054\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2658\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2659\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2660\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'load'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-02fc15b7b915>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnotes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\" | \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0mrun_episode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_episodes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault_reward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_charge\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"once\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m         \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstarting_learning_rate\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m0.0002\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PycharmProjects\\BatteryAgent\\batterydispatch\\agent\\functions\\run_episode.py\u001b[0m in \u001b[0;36mrun_episodes\u001b[1;34m(env, agent, eps, history, default_reward, random_charge, run_type)\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[1;31m# print(action)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[0mold_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m             \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdetails\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobserve_sars\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mold_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\administrator\\pycharmprojects\\gym-battery\\gym_battery\\envs\\battery_env.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    202\u001b[0m         \u001b[1;31m# Record the behavior of the system for rendering\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrid_flow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_ix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'net_flow'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet_flow\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrid_flow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_ix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'load'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_row\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    205\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrid_flow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_ix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'battery_action'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maction_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrid_flow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_ix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'state_of_charge'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbattery\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcharge\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    188\u001b[0m             \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_setitem_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_validate_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[1;34m(self, indexer, value)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m                         \u001b[1;31m# add a new item with the dtype setup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_infer_fill_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m                         new_indexer = convert_from_missing_indexer_tuple(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3368\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3369\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3370\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3372\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3444\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3445\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3446\u001b[1;33m         \u001b[0mNDFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3448\u001b[0m         \u001b[1;31m# check if we are modifying a copy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3171\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3172\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3173\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mset\u001b[1;34m(self, item, value)\u001b[0m\n\u001b[0;32m   1054\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1055\u001b[0m             \u001b[1;31m# This item wasn't present, just insert at end\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1056\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1057\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1058\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36minsert\u001b[1;34m(self, loc, item, value, allow_duplicates)\u001b[0m\n\u001b[0;32m   1170\u001b[0m             \u001b[1;31m# np.append is a lot faster, let's use it if we can.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1171\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_blklocs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_blklocs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1172\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_blknos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_blknos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1173\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1174\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_blklocs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_blklocs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36mappend\u001b[1;34m(arr, values, axis)\u001b[0m\n\u001b[0;32m   4692\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4693\u001b[0m         \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4694\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4695\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4696\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "for iteration in range(0, 30):\n",
    "    notes = 'DONT USE; Run of a DynaQ agent on Stochastic Day with seeds, run for 10,000 episodes: Seed {}'.format(iteration)\n",
    "\n",
    "    agent.set_greedy_policy(eta=0.1)\n",
    "    starting_learning_rate = 0.075\n",
    "    agent.planning_steps = 35\n",
    "    agent.patience_counter = 0\n",
    "    agent.initialize_state_actions(new_default=default_reward,\n",
    "                              do_nothing_action = act0,\n",
    "                              do_nothing_bonus = 100)    \n",
    "    \n",
    "    agent.set_seed(iteration)\n",
    "    env.set_seed(iteration)\n",
    "    \n",
    "    i=30\n",
    "\n",
    "    eps=0\n",
    "    history = []\n",
    "    while eps < 10001:\n",
    "        i+=1\n",
    "        eps+= 1\n",
    "\n",
    "        if i>30:\n",
    "            i=0\n",
    "            clear_output()\n",
    "            print(notes)\n",
    "        print(eps, end=\" | \")\n",
    "        run_episode.run_episodes(env, agent, eps, history, default_reward, random_charge = False, run_type=\"once\")\n",
    "        agent.learning_rate = starting_learning_rate * np.exp(-0.0002*eps)\n",
    "    \n",
    "    agent.set_greedy_policy(eta=0)\n",
    "    reward = run_episode.run_episodes(env, agent, eps, history, default_reward, random_charge=False, run_type='once')\n",
    "    \n",
    "    log_history.save_results(env, agent, history, reward, scenario = notes, agent_name=agent.name, notes='Iteration {}'.format(iteration))\n",
    "    \n",
    "    eps=0\n",
    "    #history = []\n",
    "    agent.learning_rate = 0\n",
    "    agent.set_greedy_policy(0)\n",
    "    while eps < 31:\n",
    "        \n",
    "        notes = 'CHECK: Run of a trained DynaQ agent on Stochastic Day: Seed {}, saving day {}'.format(iteration, eps)\n",
    "        print(notes)\n",
    "        \n",
    "        i+=1\n",
    "        eps+= 1\n",
    "\n",
    "        print(eps, end=\" | \")\n",
    "        reward = run_episode.run_episodes(env, agent, eps, history, default_reward, random_charge = False, run_type=\"once\")\n",
    "    \n",
    "        #agent.set_greedy_policy(eta=0)\n",
    "    \n",
    "        log_history.save_results(env, agent, history, reward, scenario = notes, agent_name=agent.name, notes='eps {}'.format(iteration))\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward = run_episode.run_episodes(env, agent, eps, history, default_reward, random_charge=False, run_type='once')\n",
    "reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_history.save_results(env, agent, history, reward, scenario = notes, agent_name=agent.name, notes='Iteration {}'.format(iteration))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(np.exp(-0.0002*np.arange(0,10000))*0.075)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Qs = pd.DataFrame.from_dict(agent.S_A_values, orient='index')\n",
    "Qs.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = pd.DataFrame.from_dict(agent.S_A_frequency, orient='index')\n",
    "counts.to_clipboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The agent converged after {eps} episodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agent has taken between 10 and 30 minutes, and between 700 and 2262 episodes, to converge on day 1. Optimal policy:\n",
    "Current reward of -397414.125 / -406791.825, 5600.0 / 6000.0, patience=21\n",
    "\n",
    "For 2 days, agent took 5 hours 8 minutes, and converged after 21200 episodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Then we allow the agent to take entirely greedy actions and run the algorithm to see how much the agent learned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.set_greedy_policy(eta=0)\n",
    "    \n",
    "state = env.reset(random_charge=False)\n",
    "done = False\n",
    "while not done:\n",
    "    action = agent.get_action(state, list(env.action_mapping.keys()), 0.25)\n",
    "    #print(state)\n",
    "    #action = int(input(\"action:\"))\n",
    "\n",
    "    #print(action)\n",
    "    state, reward, done, details = env.step(action)\n",
    "\n",
    "try:\n",
    "    new_demand = max(env.grid_flow.net_flow)\n",
    "    orig_demand = max(env.grid_flow.load)\n",
    "except AttributeError:\n",
    "    new_demand = \"???\"\n",
    "    orig_demand = \"???\"\n",
    "    \n",
    "    env.grid_flow['final_reward'] = reward\n",
    "    env.grid_flow['original_reward'] = default_reward\n",
    "\n",
    "\n",
    "print(f\"Current reward of {reward} / {default_reward}, {new_demand} / {orig_demand}, patience={agent.patience_counter}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = save_results(scenario='Day1_load', agent_name='DynaQ', notes=\"ran the DynaQ agent again on the Day1 data, for a second (same agent)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(DF.saved_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(DF.index.duplicated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
