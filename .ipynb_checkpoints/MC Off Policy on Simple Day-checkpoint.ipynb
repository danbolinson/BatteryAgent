{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Notebook to interact with gym-battery and battery-agent\n",
    "\n",
    "This python notebook is a working document to interact with and test the environment and the agent.\n",
    "\n",
    "Note: In order for this to work, gym-battery needs to be installed as a package, using pip install -e gym-battery from wherever gym-battery exists.\n",
    "\n",
    "The ipython notebook should exist in battery dispatch by default and should be ableto access those resources so it does not necessarily need to be build/installed using pip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import gym_battery \n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting the standard system, A10S Med busines large usage with a 2,000kW/10,000kWh battery\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('gym_battery:battery-v0', **{'N_actions':5})\n",
    "env.set_standard_system()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle\n",
    "simple_load = pd.read_pickle(\"simple_load_1d.pkl\")\n",
    "#simple_load = pd.read_clipboard()\n",
    "simple_load.value.plot()\n",
    "env.load.initialize(simple_load)\n",
    "env.fit_load_to_space()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.terminal_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: -1000.0, 1: -500.0, 2: 0.0, 3: 500.0, 4: 1000.0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the possible action mapping the agent can take\n",
    "env.action_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0.    0. 1000. 1000.]\n",
      "to\n",
      "[   24. 10000.  5000.  6000.]\n"
     ]
    }
   ],
   "source": [
    "print(env.observation_space.low)\n",
    "print(\"to\")\n",
    "print(env.observation_space.high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set how to structure the environment. 'count_days' will generate the a single day as an episode. THe number of days\n",
    "# given indicates how many differnet days to use.\n",
    "# This needs to be changed so that it generates LONGER episodes, not DIFFERENT episodes, but this hasn't been done yet.\n",
    "env.episode_type = 'count_days'\n",
    "env.run_N_episodes = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the do-nothing value for taking no action\n",
    "def dict_key_by_val(d, val):\n",
    "    for k in d.keys():\n",
    "        if d[k] == val:\n",
    "            return k\n",
    "    raise ValueError(\"value not found in dictionary\")\n",
    "    \n",
    "act0 = dict_key_by_val(env.action_mapping, 0)\n",
    "act0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Set up the agent and the discretizer.'''\n",
    "from batterydispatch.agent.agents import MonteCarloAgent\n",
    "from batterydispatch.agent.discretizers import Box_Discretizer\n",
    "\n",
    "from batterydispatch.agent.policies import do_nothing\n",
    "agent = MonteCarloAgent()\n",
    "agent.set_policy(do_nothing, {'do_nothing_action': act0})\n",
    "\n",
    "# Note, you can change the size of the state sapce by changing the number of buckets, below\n",
    "agent.set_discretizer(Box_Discretizer(env.observation_space, N=[6, 4, 12, 12]))\n",
    "agent.actions = env.action_space\n",
    "agent.learning_rate = 0.05 # used for the updates of the Q estimates\n",
    "agent.subtype = 'off-policy' # Setup the MC agent for off-policy learning\n",
    "\n",
    "global eps\n",
    "eps=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.S_A_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 4.,  8., 12., 16., 20., 24.]),\n",
       " array([ 2500.25,  5000.5 ,  7500.75, 10001.  ]),\n",
       " array([1333.41666667, 1666.83333333, 2000.25      , 2333.66666667,\n",
       "        2667.08333333, 3000.5       , 3333.91666667, 3667.33333333,\n",
       "        4000.75      , 4334.16666667, 4667.58333333, 5001.        ]),\n",
       " array([1416.75, 1833.5 , 2250.25, 2667.  , 3083.75, 3500.5 , 3917.25,\n",
       "        4334.  , 4750.75, 5167.5 , 5584.25, 6001.  ])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.discretizer.buckets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the day of data that we will be trying to learn from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\administrator\\pycharmprojects\\gym-battery\\gym_battery\\envs\\battery_env.py:160: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  self.grid_flow.set_value(self.step_ix, 'state', tuple(self.state))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011-03-07\n",
      "96\n",
      "-416388.15874999994\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "done = False\n",
    "state = env.reset()\n",
    "i = 0\n",
    "while not done:\n",
    "    i+=1\n",
    "    _,reward,done, details = env.step(act0)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(env.grid_flow.net_flow)\n",
    "try:\n",
    "    print(list(env.grid_flow.start_date)[0])\n",
    "except:\n",
    "    pass\n",
    "print(i)\n",
    "print(reward)\n",
    "default_reward = reward\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We then initialize the agent state-action estimates, based on the original billing period.\n",
    "# We also give the do_nothing action a small bonus of 100, in order to prevent the agent from arbitrarily taking action.\n",
    "agent.initialize_state_actions(new_default=default_reward,\n",
    "                              do_nothing_action = act0,\n",
    "                              do_nothing_bonus = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'do_nothing_action': 2}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.policy_args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the function to run the episodes, and run episodes until convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from batterydispatch.agent.functions import log_history, run_episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MonteCarloAgent'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We then set the final parameters guiding the episodes: The agents proclivity for random actions, \n",
    "# the number of episodes without a policy change before we can say we've converge.\n",
    "agent.set_greedy_policy(eta=0.125)\n",
    "agent.patience = 10000\n",
    "agent.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.learning_rate = 0.075\n",
    "agent.initialize_state_actions(new_default=default_reward,\n",
    "                              do_nothing_action = act0,\n",
    "                              do_nothing_bonus = 100)    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run of a Monte Carlo Off Policy agent on Simple Day with seeds, run for 10,000 episodes: Seed 13\n",
      "5271 | breaking. Action 1 not greedy at state (24.0, 2500.25, 3000.5000000000005, 4750.75) given reward -405627.0837499999, S_A_values of {0: -406974.2970052335, 1: -406894.517121183, 2: -407793.6256421891, 3: -407497.28695115476, 4: -406385.8333801562}\n",
      "Current reward of -405626 / -416388, 4500.0 / 5000.0, patience=21\n",
      "5272 | breaking. Action 2 not greedy at state (24.0, 2500.25, 3000.5000000000005, 4750.75) given reward -405733.2087499996, S_A_values of {0: -406974.2970052335, 1: -406894.517121183, 2: -407768.91691880336, 3: -407497.28695115476, 4: -406383.9204389006}\n",
      "Current reward of -405731 / -416388, 4500.0 / 5000.0, patience=22\n",
      "5273 | breaking. Action 3 not greedy at state (24.0, 2500.25, 3000.5000000000005, 4750.75) given reward -406364.35874999966, S_A_values of {0: -406974.2970052335, 1: -406894.517121183, 2: -407768.91691880336, 3: -407496.01290855906, 4: -406383.8824042672}\n",
      "Current reward of -406363 / -416388, 4500.0 / 5000.0, patience=23\n",
      "5274 | breaking. Action 0 not greedy at state (24.0, 2500.25, 3000.5000000000005, 4750.75) given reward -405732.50874999975, S_A_values of {0: -406965.4395746574, 1: -406894.517121183, 2: -407768.91691880336, 3: -407496.01290855906, 4: -406383.26663345937}\n",
      "Current reward of -405731 / -416388, 4500.0 / 5000.0, patience=24\n",
      "5275 | breaking. Action 0 not greedy at state (24.0, 2500.25, 3000.5000000000005, 4750.75) given reward -405733.0087499997, S_A_values of {0: -406950.7301528764, 1: -406894.517121183, 2: -407768.91691880336, 3: -407496.01290855906, 4: -406381.8375366703}\n",
      "Current reward of -405731 / -416388, 4500.0 / 5000.0, patience=25\n",
      "5276 | breaking. Action 3 not greedy at state (24.0, 2500.25, 3000.5000000000005, 4750.75) given reward -405416.2337499999, S_A_values of {0: -406950.7301528764, 1: -406894.517121183, 2: -407768.91691880336, 3: -407495.27921762655, 4: -406381.8375366703}\n",
      "Current reward of -405416 / -416388, 4500.0 / 5000.0, patience=26\n",
      "5277 | breaking. Action 0 not greedy at state (24.0, 2500.25, 3000.5000000000005, 4750.75) given reward -406152.90874999994, S_A_values of {0: -406947.42371607677, 1: -406894.517121183, 2: -407768.91691880336, 3: -407495.27921762655, 4: -406381.7911164912}\n",
      "Current reward of -406152 / -416388, 4500.0 / 5000.0, patience=27\n",
      "5278 | breaking. Action 1 not greedy at state (24.0, 2500.25, 3000.5000000000005, 4750.75) given reward -405943.5587499997, S_A_values of {0: -406947.42371607677, 1: -406883.3024374231, 2: -407768.91691880336, 3: -407495.27921762655, 4: -406380.68147504725}\n",
      "Current reward of -405942 / -416388, 4500.0 / 5000.0, patience=28\n",
      "5279 | breaking. Action 1 not greedy at state (24.0, 2500.25, 3000.5000000000005, 4750.75) given reward -405627.8837499997, S_A_values of {0: -406947.42371607677, 1: -406868.6698061169, 2: -407768.91691880336, 3: -407495.27921762655, 4: -406378.7809643691}\n",
      "Current reward of -405626 / -416388, 4500.0 / 5000.0, patience=29\n",
      "5280 | breaking. Action 2 not greedy at state (24.0, 2500.25, 3000.5000000000005, 4750.75) given reward -405626.6837499999, S_A_values of {0: -406947.42371607677, 1: -406868.6698061169, 2: -407762.4067424752, 3: -407495.27921762655, 4: -406378.7091120327}\n",
      "Current reward of -405626 / -416388, 4500.0 / 5000.0, patience=30\n",
      "5281 | breaking. Action 3 not greedy at state (24.0, 2500.25, 3000.5000000000005, 4750.75) given reward -406153.4087499998, S_A_values of {0: -406947.42371607677, 1: -406868.6698061169, 2: -407762.4067424752, 3: -407494.38906746136, 4: -406378.5382022859}\n",
      "Current reward of -406152 / -416388, 4500.0 / 5000.0, patience=31\n",
      "5282 | breaking. Action 3 not greedy at state (24.0, 2500.25, 3000.5000000000005, 4750.75) given reward -406258.1337499999, S_A_values of {0: -406947.42371607677, 1: -406868.6698061169, 2: -407762.4067424752, 3: -407493.9050028683, 4: -406378.52669959515}\n",
      "Current reward of -406258 / -416388, 4500.0 / 5000.0, patience=32\n",
      "5283 | breaking. Action 0 not greedy at state (24.0, 2500.25, 3000.5000000000005, 4750.75) given reward -408152.18374999997, S_A_values of {0: -406952.39603474253, 1: -406868.6698061169, 2: -407762.4067424752, 3: -407493.9050028683, 4: -406378.88403659227}\n",
      "Current reward of -408152 / -416388, 4500.0 / 5000.0, patience=33\n",
      "5284 | breaking. Action 1 not greedy at state (24.0, 2500.25, 3000.5000000000005, 4750.75) given reward -405522.5587499996, S_A_values of {0: -406952.39603474253, 1: -406854.6956621661, 2: -407762.4067424752, 3: -407493.9050028683, 4: -406377.0184530401}\n",
      "Current reward of -405521 / -416388, 4500.0 / 5000.0, patience=34\n",
      "5285 | breaking. Action 4 not greedy at state (20.0, 2500.25, 3000.5000000000005, 4750.75) given reward -405839.23374999943, S_A_values of {0: -409282.34704917815, 1: -410183.0525127231, 2: -407390.0871393178, 3: -412353.53041603434, 4: -415554.7271529702}\n",
      "Current reward of -405837 / -416388, 4500.0 / 5000.0, patience=35\n",
      "5286 | breaking. Action 1 not greedy at state (20.0, 2500.25, 3000.5000000000005, 4750.75) given reward -405522.9587499995, S_A_values of {0: -409282.34704917815, 1: -410118.5713483255, 2: -407390.0871393178, 3: -412353.53041603434, 4: -415554.7271529702}\n",
      "Current reward of -405521 / -416388, 4500.0 / 5000.0, patience=36\n",
      "5287 | breaking. Action 3 not greedy at state (24.0, 2500.25, 3000.5000000000005, 5584.25) given reward -426939.7837499998, S_A_values of {0: -426753.3651607355, 1: -426722.0737892468, 2: -426570.3046290385, 3: -426371.3621244431, 4: -426281.7723050844}\n",
      "Current reward of -426939 / -416388, 5500.0 / 5000.0, patience=37\n",
      "5288 | breaking. Action 2 not greedy at state (24.0, 2500.25, 3000.5000000000005, 4750.75) given reward -410535.35874999955, S_A_values of {0: -406952.39603474253, 1: -406854.6956621661, 2: -407798.75989024393, 3: -407493.9050028683, 4: -406385.4204833429}\n",
      "Current reward of -410533 / -416388, 4750.0 / 5000.0, patience=38\n",
      "5289 | breaking. Action 2 not greedy at state (24.0, 2500.25, 3000.5000000000005, 4750.75) given reward -405627.4837499997, S_A_values of {0: -406952.39603474253, 1: -406854.6956621661, 2: -407783.73696571874, 3: -407493.9050028683, 4: -406384.40530583804}\n",
      "Current reward of -405626 / -416388, 4500.0 / 5000.0, patience=39\n",
      "5290 | breaking. Action 2 not greedy at state (24.0, 2500.25, 3000.5000000000005, 4750.75) given reward -404469.4087499999, S_A_values of {0: -406952.39603474253, 1: -406854.6956621661, 2: -407771.594803775, 3: -407493.9050028683, 4: -406383.80269933905}\n",
      "Current reward of -404469 / -416388, 4500.0 / 5000.0, patience=40\n",
      "5291 | breaking. Action 1 not greedy at state (24.0, 2500.25, 3000.5000000000005, 4750.75) given reward -405732.2087499999, S_A_values of {0: -406952.39603474253, 1: -406849.70188383746, 2: -407771.594803775, 3: -407493.9050028683, 4: -406383.5136708066}\n",
      "Current reward of -405731 / -416388, 4500.0 / 5000.0, patience=41\n",
      "5292 | breaking. Action 3 not greedy at state (24.0, 2500.25, 3000.5000000000005, 4750.75) given reward -406258.3337499999, S_A_values of {0: -406952.39603474253, 1: -406849.70188383746, 2: -407771.594803775, 3: -407493.308011527, 4: -406383.4742505711}\n",
      "Current reward of -406258 / -416388, 4500.0 / 5000.0, patience=42\n",
      "5293 | breaking. Action 0 not greedy at state (24.0, 2500.25, 3000.5000000000005, 4750.75) given reward -407249.13375, S_A_values of {0: -406953.3847397203, 1: -406849.70188383746, 2: -407771.594803775, 3: -407493.308011527, 4: -406383.4742505711}\n",
      "Current reward of -407249 / -416388, 4500.0 / 5000.0, patience=43\n",
      "5294 | breaking. Action 3 not greedy at state (24.0, 2500.25, 3000.5000000000005, 4750.75) given reward -405942.75874999986, S_A_values of {0: -406953.3847397203, 1: -406849.70188383746, 2: -407771.594803775, 3: -407492.47603666387, 4: -406383.27884584194}\n",
      "Current reward of -405942 / -416388, 4500.0 / 5000.0, patience=44\n",
      "5295 | breaking. Action 3 not greedy at state (24.0, 2500.25, 3000.5000000000005, 6001.0) given reward -436123.0837499999, S_A_values of {0: -437424.3521045298, 1: -437166.8434414548, 2: -437131.9936840503, 3: -437149.27817646245, 4: -436316.08450269344}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-0aafeec99979>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnotes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\" | \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mrun_episode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_episodes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault_reward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_charge\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"once\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstarting_learning_rate\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m0.0002\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PycharmProjects\\BatteryAgent\\batterydispatch\\agent\\functions\\run_episode.py\u001b[0m in \u001b[0;36mrun_episodes\u001b[1;34m(env, agent, eps, history, default_reward, random_charge, run_type)\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobserve_sars\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mold_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m             \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend_episode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mPolicyConvergedError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[0mconverged\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PycharmProjects\\BatteryAgent\\batterydispatch\\agent\\agents.py\u001b[0m in \u001b[0;36mend_episode\u001b[1;34m(self, reward)\u001b[0m\n\u001b[0;32m    545\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpatience\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_policy_convergence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpast_S_A_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mS_A_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PycharmProjects\\BatteryAgent\\batterydispatch\\agent\\agents.py\u001b[0m in \u001b[0;36mcheck_policy_convergence\u001b[1;34m(self, increment_patience)\u001b[0m\n\u001b[0;32m    108\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mPolicyConvergedError\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpast_S_A_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mS_A_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mset_greedy_policy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcopier\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    238\u001b[0m     \u001b[0mmemo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 240\u001b[1;33m         \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    241\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_deepcopy_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcopier\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    238\u001b[0m     \u001b[0mmemo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 240\u001b[1;33m         \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    241\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_deepcopy_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m     \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "for iteration in range(30):\n",
    "    notes = 'Run of a Monte Carlo Off Policy agent on Simple Day with seeds, run for 10,000 episodes: Seed {}'.format(iteration)\n",
    "\n",
    "    agent.set_greedy_policy(eta=0.1)\n",
    "    starting_learning_rate = 0.075\n",
    "    agent.patience_counter = 0\n",
    "    agent.initialize_state_actions(new_default=default_reward,\n",
    "                              do_nothing_action = act0,\n",
    "                              do_nothing_bonus = 100)    \n",
    "    \n",
    "    agent.set_seed(iteration)\n",
    "    env.set_seed(iteration)\n",
    "    \n",
    "    i=30\n",
    "\n",
    "    eps=0\n",
    "    history = []\n",
    "    while eps < 10001:\n",
    "        i+=1\n",
    "        eps+= 1\n",
    "\n",
    "        if i>30:\n",
    "            i=0\n",
    "            clear_output()\n",
    "            print(notes)\n",
    "        print(eps, end=\" | \")\n",
    "        run_episode.run_episodes(env, agent, eps, history, default_reward, random_charge = False, run_type=\"once\")\n",
    "        agent.learning_rate = starting_learning_rate * np.exp(-0.0002*eps)\n",
    "    \n",
    "    agent.set_greedy_policy(eta=0)\n",
    "    reward = run_episode.run_episodes(env, agent, eps, history, default_reward, random_charge=False, run_type='once')\n",
    "    \n",
    "    log_history.save_results(env, agent, history, reward, scenario = notes, agent_name=agent.name, notes='Iteration {}'.format(iteration))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the state-action value estimates\n",
    "val = agent.S_A_values.copy()\n",
    "val = pd.DataFrame.from_dict(val, orient='index')\n",
    "val = val.reset_index()\n",
    "val['state'] = [[i.level_0, i.level_1, i.level_2, i.level_3] for ix, i in val.iterrows()]\n",
    "val = val.rename(columns={\"state\": \"agent_state\"})\n",
    "val.index = val.agent_state\n",
    "val = val.drop(columns=['level_0', 'level_1', 'level_2', 'level_3', 'agent_state'])\n",
    "val.index = [tuple(x) for x in val.index]\n",
    "\n",
    "val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward = run_episode.run_episodes(env, agent, eps, history, default_reward, random_charge=False, run_type='once')\n",
    "reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_history.save_results(env, agent, history, reward, scenario = notes, agent_name=agent.name, notes='Iteration {}'.format(iteration))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(np.exp(-0.0002*np.arange(0,10000))*0.075)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Qs = pd.DataFrame.from_dict(agent.S_A_values, orient='index')\n",
    "Qs.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = pd.DataFrame.from_dict(agent.S_A_frequency, orient='index')\n",
    "counts.to_clipboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The agent converged after {eps} episodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agent has taken between 10 and 30 minutes, and between 700 and 2262 episodes, to converge on day 1. Optimal policy:\n",
    "Current reward of -397414.125 / -406791.825, 5600.0 / 6000.0, patience=21\n",
    "\n",
    "For 2 days, agent took 5 hours 8 minutes, and converged after 21200 episodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Then we allow the agent to take entirely greedy actions and run the algorithm to see how much the agent learned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.set_greedy_policy(eta=0)\n",
    "    \n",
    "state = env.reset(random_charge=False)\n",
    "done = False\n",
    "while not done:\n",
    "    action = agent.get_action(state, list(env.action_mapping.keys()), 0.25)\n",
    "    #print(state)\n",
    "    #action = int(input(\"action:\"))\n",
    "\n",
    "    #print(action)\n",
    "    state, reward, done, details = env.step(action)\n",
    "\n",
    "try:\n",
    "    new_demand = max(env.grid_flow.net_flow)\n",
    "    orig_demand = max(env.grid_flow.load)\n",
    "except AttributeError:\n",
    "    new_demand = \"???\"\n",
    "    orig_demand = \"???\"\n",
    "    \n",
    "    env.grid_flow['final_reward'] = reward\n",
    "    env.grid_flow['original_reward'] = default_reward\n",
    "\n",
    "\n",
    "print(f\"Current reward of {reward} / {default_reward}, {new_demand} / {orig_demand}, patience={agent.patience_counter}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = save_results(scenario='Day1_load', agent_name='DynaQ', notes=\"ran the DynaQ agent again on the Day1 data, for a second (same agent)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(DF.saved_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(DF.index.duplicated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
